---
title: "Inital Analysis"
format: html
editor: source
---
# set up
```{r}
library(tidyverse)
library(janitor)
library(ggplot2)

library(tidytext)
library(SnowballC)
library(tm)
library(stm)

```


```{r}
load("data/trans_news_final.Rda")
```

```{r}
final_df <- final_df |>
  mutate(
    day = as.numeric(publication_date - as.Date('1980-06-12'))
  ) |>
  filter(!is.na(publication_date),
         section!="espanol")
```


# Ingest and Prepare
```{r}
sw <- tidytext::stop_words |>
  bind_rows(
    as.data.frame(
      list(word = c("pm", "am", "ms", "la", "de", "el"))
    )
  ) |>
  mutate(
    word =  str_to_lower(word) |>
            removePunctuation() |>
            removeNumbers() |>
            str_remove_all("[:space:]") |>
            str_trim(side="both")
  ) |>
  distinct(word, .keep_all = TRUE)
```


```{r}
tidy_news <- final_df |>
  unnest_tokens(word, full_text)
  

```

```{r}
  
  
```

```{r}
tidy_counts <- tidy_news |>
  count(id, word, sort = TRUE) |>
  mutate(
    word = str_remove_all(word, "[[:punct:]]"),
    stem = case_when(str_detect(word, "[^e|aies$]ies$") ~ str_replace(word, "ies$", "y"),
        str_detect(word, "[^e|a|oes$]es$") ~ str_replace(word, "es$", "e"),
        str_detect(word, "[^ss$|us$]s$") ~ str_remove(word, "s$"),
        TRUE ~ word)
  ) |>
  anti_join(sw) |>
  anti_join(sw, by = join_by(stem==word))
```

```{r}
tidy_counts |>
  filter(str_detect(word, "dont"))
```

## stm formatting
```{r}
library(quanteda)

trans_meta <- final_df |>
  select(
    doc_id,
    publisher,
    day
  )

trans_stm <- tidy_counts |>
  cast_dfm(id, stem, n) |>
  convert(
    to = "stm",
    docvars = trans_meta
  )

```

```{r}
#test
plotRemoved(trans_stm$documents, lower.thresh = seq(1, 20, by = 1))
```

```{r}
out <- prepDocuments(trans_stm$documents, trans_stm$vocab, trans_stm$meta, lower.thresh = 5)
```

```{r}
first_mod <- stm(
  documents = out$documents,
  vocab = out$vocab,
  K = 40,
  prevalence = ~s(day),
  max.em.its = 75,
  data = out$meta,
  init.type = "Spectral",
  verbose = TRUE
)
```

```{r}
plot(first_mod)
```


```{r}
findThoughts(first_mod, final_df$full_text, n = 4, topics = 3)
```


```{r}
storek <- searchK(
  documents = out$documents,
  vocab = out$vocab,
  K = seq(20, 100, by=20),
  prevalence = ~s(day),
  max.em.its = 75,
  data = out$meta,
  init.type = "Spectral",
  verbose = TRUE,
)
```



```{r}
plot(storek)
```

