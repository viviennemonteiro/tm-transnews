---
title: "Inital Analysis"
format: html
editor: source
---
# set up
```{r}
library(tidyverse)
library(janitor)
library(ggplot2)

library(tidytext)
library(SnowballC)
library(tm)
library(stm)

```


```{r}
load("data/trans_news_final.Rda")
```

```{r}
final_df <- final_df |>
  mutate(
    day = as.numeric(publication_date - as.Date('1980-06-12')),
    trans_mentions = str_count(full_text, "trans|transgender[.*][ \\.$?!]|transexual|tranny|transvestite")
  ) |>
  filter(!is.na(publication_date),
         section!="espanol")
```

```{r}
summary(final_df$trans_mentions)
```


# Ingest and Prepare
```{r}
sw <- tidytext::stop_words |>
  bind_rows(
    as.data.frame(
      list(word = c("pm", "am", "ms", "la", "de", "el"))
    )
  ) |>
  mutate(
    word =  str_to_lower(word) |>
            removePunctuation() |>
            removeNumbers() |>
            str_remove_all("[:space:]") |>
            str_trim(side="both")
  ) |>
  distinct(word, .keep_all = TRUE)
```


```{r}
tidy_news <- final_df |>
  unnest_tokens(word, full_text)
  

```

```{r}
tidy_counts <- tidy_news |>
  count(id, word, sort = TRUE) |>
  mutate(
    word = str_remove_all(word, "[[:punct:]]"),
    stem = case_when(str_detect(word, "[^e|aies$]ies$") ~ str_replace(word, "ies$", "y"),
        str_detect(word, "[^e|a|oes$]es$") ~ str_replace(word, "es$", "e"),
        str_detect(word, "[^ss$|us$]s$") ~ str_remove(word, "s$"),
        TRUE ~ word)
  ) |>
  anti_join(sw) |>
  anti_join(sw, by = join_by(stem==word))
```


## stm formatting
```{r}
library(quanteda)

trans_meta <- final_df |>
  select(
    doc_id,
    publisher,
    day,
    trans_mentions
  )

trans_stm <- tidy_counts |>
  cast_dfm(id, stem, n) |>
  convert(
    to = "stm",
    docvars = trans_meta
  )

```

```{r}
#test
plotRemoved(trans_stm$documents, lower.thresh = seq(1, 20, by = 1))
```

```{r}
out <- prepDocuments(trans_stm$documents, trans_stm$vocab, trans_stm$meta, lower.thresh = 5)
```

```{r}
first_mod <- stm(
  documents = out$documents,
  vocab = out$vocab,
  K = 40,
  prevalence = ~s(day),
  max.em.its = 75,
  data = out$meta,
  init.type = "Spectral",
  verbose = TRUE
)
```

```{r}
plot(first_mod)
```


```{r}
findThoughts(first_mod, final_df$full_text, n = 4, topics = 3)
```


```{r}
storek <- searchK(
  documents = out$documents,
  vocab = out$vocab,
  K = seq(20, 100, by=20),
  prevalence = ~s(day),
  max.em.its = 75,
  data = out$meta,
  init.type = "Spectral",
  verbose = TRUE,
)
```

# evaluate

```{r}
dialk <- searchK(
  documents = out$documents,
  vocab = out$vocab,
  K = seq(20, 40, by=5),
  prevalence = ~s(day),
  max.em.its = 50,
  data = out$meta,
  init.type = "Spectral",
  verbose = TRUE,
)
```

```{r}
plot(storek)
```


```{r}
plot(dialk)
```

```{r}
tibble(storek$results) |>
  bind_rows(dialk$results) |>
  mutate_all(
    as.numeric
  ) |>
ggplot(aes(x=semcoh, y=exclus, label=K)) +
  geom_label()
```

```{r}
dialk
```


```{r}
model_k30_nometa <- stm(
  documents = out$documents,
  vocab = out$vocab,
  K = 30,
  #prevalence = ~s(day),
  max.em.its = 100,
  data = out$meta,
  init.type = "Spectral",
  verbose = TRUE
)
```


```{r}
model_k30 <- stm(
  documents = out$documents,
  vocab = out$vocab,
  K = 30,
  prevalence = ~s(day),
  max.em.its = 100,
  data = out$meta,
  init.type = "Spectral",
  verbose = TRUE
)
```


```{r}
plot(model_k30, type = "summary", xlim = c(0, 0.10))
```
```{r}
labelTopics(model_k30)
```

```{r}
estimateEffect(1:30 ~ s(day), model_k30, meta = out$meta, uncertainty = "Global") |>
  summary(topics = 1)

```

